{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hulu-tv_data.csv\n",
      "hbo-max_data.csv\n",
      "paramount-tv_data.csv\n",
      "disney-+_data.csv\n",
      "crunchyroll_data.csv\n",
      "rakuten-viki-tv_data.csv\n",
      "dark-matter-tv_data.csv\n",
      "netflix_data.csv\n",
      "amazon-prime_data.csv\n",
      "Closest file: netflix_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from ast import literal_eval\n",
    "import datetime\n",
    "import time  # for timing\n",
    "import joblib # for saving objects\n",
    "\n",
    "\n",
    "TESTING = True\n",
    "REGENERATE = False\n",
    "\n",
    "if TESTING:\n",
    "    dataset_name = 'netflix'\n",
    "else:\n",
    "    dataset_name = input(\"Enter dataset name: \")\n",
    "\n",
    "# Search file with levinstein distance\n",
    "\n",
    "dataset_files = []\n",
    "for root, dirs, files in os.walk(\"data\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            dataset_files.append(file)\n",
    "\n",
    "\n",
    "def calculate_levenshtein(str1, str2):\n",
    "    replacementCost = [[]]\n",
    "\n",
    "    for i in range(len(str1) + 1):\n",
    "        replacementCost.append([])\n",
    "        for j in range(len(str2) + 1):\n",
    "            if i == 0:\n",
    "                replacementCost[i].append(j)\n",
    "            elif j == 0:\n",
    "                replacementCost[i].append(i)\n",
    "            elif str1[i - 1] == str2[j - 1]:\n",
    "                replacementCost[i].append(replacementCost[i - 1][j - 1])\n",
    "            else:\n",
    "                replacementCost[i].append(1 + min(replacementCost[i - 1][j], replacementCost[i][j - 1],\n",
    "                                                  replacementCost[i - 1][j - 1]))\n",
    "\n",
    "    return replacementCost[len(str1)][len(str2)]\n",
    "\n",
    "\n",
    "# Find the closest file\n",
    "scores = []\n",
    "\n",
    "for file in dataset_files:\n",
    "    print(file)\n",
    "    scores.append(calculate_levenshtein(dataset_name, file.split(\"_data\")[0]))\n",
    "\n",
    "closest_file_name = dataset_files[scores.index(min(scores))]\n",
    "print(\"Closest file: \" + closest_file_name)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"data/\" + closest_file_name)\n",
    "\n",
    "df = df.drop(columns=[\"imdb_id\"])\n",
    "\n",
    "# print(df)\n",
    "df[\"score_avg\"] = (df[\"imdb_score\"] + df[\"tmdb_score\"]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Progressbar:\n",
    "\n",
    "    def __init__(self, maxValue, startTime=time.time()):\n",
    "        self.startTime = startTime\n",
    "        self.maxValue = maxValue\n",
    "\n",
    "    def update(self, index):\n",
    "        valueLength = len(str(self.maxValue))\n",
    "        indexString = str(index)\n",
    "        # while len(str(indexString)) < valueLength:\n",
    "        #     indexString = \" \" + indexString\n",
    "\n",
    "        indexString.rjust(valueLength - len(indexString))\n",
    "\n",
    "        print(\"\\rProgress: [{0:50s}] {1:.1f}%\".format('#' * int((index + 1) * 50 / self.maxValue), (index + 1) * 100 / self.maxValue)\n",
    "              + \"    \" + indexString + \"/\" + str(self.maxValue) + \"    \" +\n",
    "              \"Time left: {}\".format(str(datetime.timedelta(seconds=(self.maxValue - (index + 1)) * (time.time() - self.startTime) / (index + 1)))), end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_genres = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    row[\"genres\"] = literal_eval(row[\"genres\"])\n",
    "    for genre in row[\"genres\"]:\n",
    "        if genre not in unique_genres:\n",
    "            unique_genres.append(genre)\n",
    "\n",
    "df[\"genres_index\"] = df[\"genres\"].apply(lambda x: [unique_genres.index(i) for i in literal_eval(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_production_countries = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    row[\"production_countries\"] = literal_eval(row[\"production_countries\"])\n",
    "    for production_country in row[\"production_countries\"]:\n",
    "        if production_country not in unique_production_countries:\n",
    "            unique_production_countries.append(production_country)\n",
    "\n",
    "df[\"production_countries_index\"] = df[\"production_countries\"].apply(\n",
    "    lambda x: [unique_production_countries.index(i) for i in literal_eval(x)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_types = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row[\"type\"] not in unique_types:\n",
    "        unique_types.append(row[\"type\"])\n",
    "\n",
    "df[\"type_index\"] = df[\"type\"].apply(lambda x: unique_types.index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_age_certifications = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row[\"age_certification\"] not in unique_age_certifications:\n",
    "        unique_age_certifications.append(row[\"age_certification\"])\n",
    "\n",
    "df[\"age_certification_index\"] = df[\"age_certification\"].apply(\n",
    "    lambda x: unique_age_certifications.index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [##################################################] 100.0%    5805/5806    Time left: 0:00:00.019032"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>release_year</th>\n",
       "      <th>age_certification</th>\n",
       "      <th>runtime</th>\n",
       "      <th>genres</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>seasons</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>imdb_votes</th>\n",
       "      <th>tmdb_popularity</th>\n",
       "      <th>tmdb_score</th>\n",
       "      <th>score_avg</th>\n",
       "      <th>genres_index</th>\n",
       "      <th>production_countries_index</th>\n",
       "      <th>type_index</th>\n",
       "      <th>age_certification_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, title, type, description, release_year, age_certification, runtime, genres, production_countries, seasons, imdb_score, imdb_votes, tmdb_popularity, tmdb_score, score_avg, genres_index, production_countries_index, type_index, age_certification_index]\n",
       "Index: []"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_splitted = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "progressBar = Progressbar(len(df))\n",
    "\n",
    "save_name = \"saved/splitted_data_\" + \\\n",
    "    dataset_name.split(\".\")[0].split(\"_\")[0] + \".df\"\n",
    "\n",
    "if REGENERATE or not os.path.exists(save_name):\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        progressBar.update(index)\n",
    "\n",
    "        for genre_index in row[\"genres_index\"]:\n",
    "            row_copy = row.copy()\n",
    "            row_copy[\"genres_index\"] = genre_index\n",
    "\n",
    "            for production_country_index in row_copy[\"production_countries_index\"]:\n",
    "                row_copy2 = row_copy.copy()\n",
    "                row_copy2[\"production_countries_index\"] = production_country_index        \n",
    "\n",
    "                # df_splitted = df_splitted.append(pd.DataFrame(data=row_copy2))\n",
    "                # df_splitted = pd.concat([df_splitted, pd.DataFrame(data=row_copy2)])\n",
    "\n",
    "                df.loc[len(df.index)] = row_copy2\n",
    "\n",
    "            # df_splitted = pd.concat([df_splitted, pd.DataFrame(data=row_copy)])\n",
    "            \n",
    "    joblib.dump(df_splitted, save_name)\n",
    "else:\n",
    "    df_splitted = joblib.load(save_name)\n",
    "\n",
    "df_splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>release_year</th>\n",
       "      <th>age_certification</th>\n",
       "      <th>runtime</th>\n",
       "      <th>genres</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>seasons</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>imdb_votes</th>\n",
       "      <th>tmdb_popularity</th>\n",
       "      <th>tmdb_score</th>\n",
       "      <th>score_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>ts160526</td>\n",
       "      <td>Khawatir</td>\n",
       "      <td>SHOW</td>\n",
       "      <td>A TV show devoted to help young people to be m...</td>\n",
       "      <td>2005</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>20</td>\n",
       "      <td>['reality']</td>\n",
       "      <td>[]</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>3046.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2927</th>\n",
       "      <td>ts265844</td>\n",
       "      <td>#ABtalks</td>\n",
       "      <td>SHOW</td>\n",
       "      <td>#ABtalks is a YouTube interview show hosted by...</td>\n",
       "      <td>2018</td>\n",
       "      <td>TV-PG</td>\n",
       "      <td>68</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>ts4</td>\n",
       "      <td>Breaking Bad</td>\n",
       "      <td>SHOW</td>\n",
       "      <td>When Walter White, a New Mexico chemistry teac...</td>\n",
       "      <td>2008</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>48</td>\n",
       "      <td>['drama', 'thriller', 'crime']</td>\n",
       "      <td>['US']</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1727694.0</td>\n",
       "      <td>337.419</td>\n",
       "      <td>8.8</td>\n",
       "      <td>9.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id         title  type  \\\n",
       "656   ts160526      Khawatir  SHOW   \n",
       "2927  ts265844      #ABtalks  SHOW   \n",
       "243        ts4  Breaking Bad  SHOW   \n",
       "\n",
       "                                            description  release_year  \\\n",
       "656   A TV show devoted to help young people to be m...          2005   \n",
       "2927  #ABtalks is a YouTube interview show hosted by...          2018   \n",
       "243   When Walter White, a New Mexico chemistry teac...          2008   \n",
       "\n",
       "     age_certification  runtime                          genres  \\\n",
       "656              TV-14       20                     ['reality']   \n",
       "2927             TV-PG       68                              []   \n",
       "243              TV-MA       48  ['drama', 'thriller', 'crime']   \n",
       "\n",
       "     production_countries  seasons  imdb_score  imdb_votes  tmdb_popularity  \\\n",
       "656                    []     11.0         9.6      3046.0              NaN   \n",
       "2927                   []      1.0         9.6         7.0              NaN   \n",
       "243                ['US']      5.0         9.5   1727694.0          337.419   \n",
       "\n",
       "      tmdb_score  score_avg  \n",
       "656          NaN        NaN  \n",
       "2927         NaN        NaN  \n",
       "243          8.8       9.15  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the top 3 movies with the highest Imdb_score\n",
    "df.sort_values(by=[\"imdb_score\"], ascending=False, inplace=True)\n",
    "\n",
    "# visualize the data\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/davidemarcoli/coding/nyp/259/streaming-data/analyzer.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/davidemarcoli/coding/nyp/259/streaming-data/analyzer.ipynb#ch0000008?line=1'>2</a>\u001b[0m X \u001b[39m=\u001b[39m df_splitted\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mscore_avg\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdescription\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/davidemarcoli/coding/nyp/259/streaming-data/analyzer.ipynb#ch0000008?line=2'>3</a>\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mgenres\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mproduction_countries\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mage_certification\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/davidemarcoli/coding/nyp/259/streaming-data/analyzer.ipynb#ch0000008?line=3'>4</a>\u001b[0m y \u001b[39m=\u001b[39m df_splitted[\u001b[39m'\u001b[39m\u001b[39mscore_avg\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/davidemarcoli/coding/nyp/259/streaming-data/analyzer.ipynb#ch0000008?line=4'>5</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/davidemarcoli/coding/nyp/259/streaming-data/analyzer.ipynb#ch0000008?line=6'>7</a>\u001b[0m model \u001b[39m=\u001b[39m DecisionTreeClassifier()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/davidemarcoli/coding/nyp/259/streaming-data/analyzer.ipynb#ch0000008?line=7'>8</a>\u001b[0m model\u001b[39m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/anaconda3/envs/uk259/lib/python3.9/site-packages/sklearn/model_selection/_split.py:2424\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   <a href='file:///home/davidemarcoli/anaconda3/envs/uk259/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2420'>2421</a>\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39marrays)\n\u001b[1;32m   <a href='file:///home/davidemarcoli/anaconda3/envs/uk259/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2422'>2423</a>\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[0;32m-> <a href='file:///home/davidemarcoli/anaconda3/envs/uk259/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2423'>2424</a>\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   <a href='file:///home/davidemarcoli/anaconda3/envs/uk259/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2424'>2425</a>\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39;49m\u001b[39m0.25\u001b[39;49m\n\u001b[1;32m   <a href='file:///home/davidemarcoli/anaconda3/envs/uk259/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2425'>2426</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///home/davidemarcoli/anaconda3/envs/uk259/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2427'>2428</a>\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/davidemarcoli/anaconda3/envs/uk259/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2428'>2429</a>\u001b[0m     \u001b[39mif\u001b[39;00m stratify \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/uk259/lib/python3.9/site-packages/sklearn/model_selection/_split.py:2102\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   <a href='file:///home/davidemarcoli/anaconda3/envs/uk259/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2098'>2099</a>\u001b[0m n_train, n_test \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(n_train), \u001b[39mint\u001b[39m(n_test)\n\u001b[1;32m   <a href='file:///home/davidemarcoli/anaconda3/envs/uk259/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2100'>2101</a>\u001b[0m \u001b[39mif\u001b[39;00m n_train \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> <a href='file:///home/davidemarcoli/anaconda3/envs/uk259/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2101'>2102</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   <a href='file:///home/davidemarcoli/anaconda3/envs/uk259/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2102'>2103</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWith n_samples=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, test_size=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m and train_size=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///home/davidemarcoli/anaconda3/envs/uk259/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2103'>2104</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///home/davidemarcoli/anaconda3/envs/uk259/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2104'>2105</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maforementioned parameters.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   <a href='file:///home/davidemarcoli/anaconda3/envs/uk259/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2105'>2106</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///home/davidemarcoli/anaconda3/envs/uk259/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=2107'>2108</a>\u001b[0m \u001b[39mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "# Split in train and test set\n",
    "X = df_splitted.drop(columns=['id', 'score_avg', 'title', 'description',\n",
    "                     'genres', 'production_countries', 'type', 'age_certification'])\n",
    "y = df_splitted['score_avg']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "score = accuracy_score(y_test, predictions)\n",
    "score\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b07399c1214139f4e29b995fc9456ffec3c6726a6e7f1ca196954ea28f63d1dc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('uk259')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
